{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp pcitpy\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pcitpy.family_of_curves import family_of_curves\n",
    "\n",
    "\n",
    "def simulate_data(analysis_id, noise_knob, curve_type, yval_distribution, net_effects, varargin):\n",
    "    \"\"\"Generate simulated data from a ground truth curve.\n",
    "    \n",
    "    This function gets the curve related information from `family of curves` \n",
    "    and `common to all curves`. You can change the number of subjects, items \n",
    "    per subject and other defaults in the simulate data.m to be similar to \n",
    "    your dataset. This function generates simulated data from both Bernoulli \n",
    "    and normal distributions.\n",
    "    \n",
    "    **Arguments**:  \n",
    "    - analysis_id: Valid analysis Id. NOTE will need to end in sim\n",
    "    - noise_knob: variance in noise added to activations\n",
    "    - curve_type: valid curve type listed in `show_bcm_curve_beta`\n",
    "    - yval_distribution: distribution of yvals. Right now the code supports \n",
    "        'bernoulli' and 'normal'\n",
    "    - net effects: If > 1, those many repetitions will be sampled per item. If \n",
    "        <= 0 then only one repetition per item\n",
    "    - varargin = vector of inputs depending on the curve / 'con' or 'inc'\n",
    "    \n",
    "    **Creates** simulated_data.mat\n",
    "    \n",
    "    **Example usage**:  \n",
    "    Note the order of the curve parameters [y1, x1, x2, y2, y3, y4]  \n",
    "    `simulate_data('my_analysis_id', 0.001, 'horz_indpnt', 'bernoulli', 10, \n",
    "        [0.6, 0.2, 0.5, -0.4, 0.5, 0.9])`\n",
    "    `simulate_data('my_analysis_id', 0.001, 'horz_indpnt', 'bernoulli', 10, \n",
    "        'con') - for a consistent curve`\n",
    "    `simulate_data('my_analysis_id', 0.001, 'horz_indpnt', 'bernoulli', 10, \n",
    "        'inc') - for an inconsistent curve`\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the correct number of arguments are passed in (may not need this, python has automatic error)\n",
    "    if len(varargin) < 6:\n",
    "        raise Exception('Missing input parameters')\n",
    "\n",
    "    # Generating a random number (numpy automatically does this based on system clock)\n",
    "    np.random.seed()\n",
    "\n",
    "    # Getting current directory\n",
    "    curr_dir = os.getcwd()\n",
    "\n",
    "    # Setting the target directory\n",
    "    results_dir = curr_dir + '/pcit_test/results'\n",
    "    target_dir = results_dir + analysis_id\n",
    "\n",
    "    # Create the results, target folder if it doesn't exist\n",
    "    if os.path.isdir(results_dir) == False:\n",
    "        os.makedirs(results_dir)\n",
    "    if os.path.isdir(target_dir) == False:\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # Setting the number of subjects\n",
    "    nSubjects = 35\n",
    "\n",
    "    # Setting the number of samples per subject\n",
    "    nItems = 8\n",
    "\n",
    "    #Setting the item_spread = .15, to ensure each sample repetitions (i.e. items) have at least .15 spread\n",
    "    item_spread = 0.15\n",
    "\n",
    "    # Setting the resolution\n",
    "    resolution = 4\n",
    "\n",
    "    # Draw a curve and get the x, y values and curve parameters\n",
    "    if curve_type == 'con' or curve_type == 'inc':\n",
    "        curve_params = common_to_all_curves(curve_type, 'auto_generate', varargin[0], resolution)\n",
    "    elif isinstance(varargin, list):\n",
    "        curve_params = np.array((varargin))\n",
    "        # out = 100\n",
    "    else:\n",
    "        raise ValueError('Invalid varargin! The valid arguments are \"con\", \"inc\" or [y1, x1, x2, y2, y3, y4]');\n",
    "\n",
    "    out = family_of_curves(curve_type, 'get_curve_xy_vals', curve_params)\n",
    "\n",
    "\n",
    "    # House keeping\n",
    "    subj_id_list = [];\n",
    "    item_list = [];\n",
    "    predictor_var_list = [];\n",
    "    dependent_var_list = [];\n",
    "    net_effects_list = [];\n",
    "    net_eff_counter = 1;\n",
    "\n",
    "    # For each subject\n",
    "    for sub in range(nSubjects):\n",
    "        subj_obs = [];\n",
    "        yvals = []\n",
    "        if net_effects > 0:\n",
    "            tmp_net_effects_list = [];\n",
    "\n",
    "            # Uniformly sample 'nItems' items per subject between item_spread and (1- item_spread)\n",
    "            # Now the [item_spread, (1-item_spread)] boundary case comes from the fact you are going to sample\n",
    "            # net effects for each item as 'each item +/- item_spread' bin boundary.\n",
    "            subj_act_means = np.random.uniform(item_spread, (1-item_spread), nItems);\n",
    "\n",
    "            # For each item, sample 'net_effects' amount of net effects\n",
    "            for m in range(len(subj_act_means)):\n",
    "                subj_obs = [subj_obs, np.random.uniform(subj_act_means[m]-item_spread, subj_act_means[m]+item_spread, net_effects)]\n",
    "\n",
    "\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "\n",
    "sys.path.insert(0, '/Users/Arlene1/Documents')\n",
    "\n",
    "#output_name = '../data/results/'\n",
    "\n",
    "#importance_sampler_mat = output_name + 'analysis-sim-2c_importance_sampler'\n",
    "#importance_sampler_mat = scipy.io.loadmat(importance_sampler_mat)\n",
    "\n",
    "simulate_data('my_analysis_id', 0.001, 'horz_indpnt', 'bernoulli', 10, [0.6, 0.2, 0.5, -0.4, 0.5, 0.9])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
