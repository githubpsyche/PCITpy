{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp family_of_curves\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "from PCITpy.family_of_distributions import family_of_distributions\n",
    "\n",
    "\n",
    "def family_of_curves(curve_type, get_info, *varargin):\n",
    "    \"\"\"Provides curve specific computations like number of curve parameters, \n",
    "    boundaries, log likelihood, etc. Only supports 'horz_indpnt' natively.\n",
    "\n",
    "    **Arguments**:  \n",
    "    - curve_type: Family of curves, string, e.g. 'horz_indpnt'\n",
    "    - get_info: Cues for specific information / computation, string, e.g. \n",
    "        'get_nParams'\n",
    "    - varargin: Is either empty or has arguments depending on the computation\n",
    "\n",
    "    **Returns** the output of all computations.\n",
    "    \"\"\"\n",
    "    if curve_type == 'horz_indpnt':\n",
    "        return horz_indpnt_curve(get_info, varargin)\n",
    "    else:\n",
    "        raise ValueError('Invalid curve!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(family_of_curves, title_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def horz_indpnt_curve(get_info, input_params):\n",
    "    \"\"\"Provides curve-specific computations for the curve type \n",
    "    `horz_indpnt_curve`.\n",
    "    \n",
    "    Only called via `family_of_curves` within the toolbox. \n",
    "    Order of curve parameters: y1, x1, x2, y2, y3 and y4. x1 must always \n",
    "    precede x2 (when passing in curve parameters as well as when plotting).\n",
    "    \"\"\"\n",
    "\n",
    "    nParam = 6\n",
    "    curve_type = 'horz_indpnt'\n",
    "\n",
    "    if get_info == 'get_nParams':  # --> (1), number of curve parameters\n",
    "        return nParam\n",
    "\n",
    "    # --> (2), Absolute boundaries of the curve parameters\n",
    "    elif get_info == 'get_bounds':  \n",
    "        return np.array([[-1, 1], [0, 1], [0, 1], [-1, 1], [-1, 1], [-1, 1]])\n",
    "\n",
    "    # --> (3), Indices of vertical parameters i.e. the ones corresponding to \n",
    "    # v* in the order of curve parameters\n",
    "    elif get_info == 'get_vertical_params_only':\n",
    "        return np.array([0, 3, 4, 5])\n",
    "\n",
    "    # --> (4), Indices of horizontal parameters i.e. the ones corresponding to \n",
    "    # h* in the order of curve parameters\n",
    "    elif get_info == 'get_horizontal_params_only':\n",
    "        return np.array([1, 2])\n",
    "\n",
    "    # --> (5), Get the curve y-vals (with or without net effects) for each of \n",
    "    # the P particle curves and then compute the log probability mass function \n",
    "    # (pmf)\n",
    "    elif get_info == 'compute_likelihood':\n",
    "        return compute_horz_indpnt_likelihood(input_params)\n",
    "\n",
    "    # --> (6), Use some criterion to carve out the curve space into theory \n",
    "    # consistent and theory inconsistent\n",
    "    elif get_info == 'count_particles':\n",
    "        return count_horz_indpnt_particles(input_params)\n",
    "    \n",
    "    # --> (7), This is the same as compute_likelihood in the sense map the \n",
    "    # predictor variable to the curve y val but there are some differences.\n",
    "    # 1. We only know the curve parameters and we have to map all the\n",
    "    # x_values (0-to-1) to the curve y values where as in compute_likelihood \n",
    "    # we had specific x values (predictor variables) and curve parameters 2. \n",
    "    # There is NO net effect cluster concept here 3. We DO NOT compute the pmf \n",
    "    # as well. Hence parts of the code will look similar but we felt these two \n",
    "    # chunks of code will need to be separate\n",
    "    elif get_info == 'get_curve_xy_vals':\n",
    "        return get_horz_indpnt_curve_xy_vals(input_params)\n",
    "    else:\n",
    "        raise ValueError('Invalid operation!')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(horz_indpnt_curve, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def compute_horz_indpnt_likelihood(input_params):\n",
    "    \"\"\"Get the curve y-vals (with or without net effects) for each of the P \n",
    "    particle curves and then compute the log probability mass function (pmf).\"\"\"\n",
    "    \n",
    "    if len(input_params) <= 5:\n",
    "        raise ValueError('Missing input parameters!')\n",
    "\n",
    "    net_effect_clusters = input_params[0]\n",
    "    particles = int(input_params[1])\n",
    "    y1 = input_params[2][:, 0]\n",
    "    x1 = input_params[2][:, 1]\n",
    "    x2 = input_params[2][:, 2]\n",
    "    y2 = input_params[2][:, 3]\n",
    "    y3 = input_params[2][:, 4]\n",
    "    y4 = input_params[2][:, 5]\n",
    "    b0 = input_params[3][0]\n",
    "    b1 = input_params[3][1]\n",
    "    data = input_params[4]\n",
    "    distribution = input_params[5]\n",
    "    dist_specific_params = input_params[6]\n",
    "\n",
    "    data_matrix_columns = input_params[7]\n",
    "    predictor_var_column = data_matrix_columns['predictor_var']\n",
    "    dependent_var_column = data_matrix_columns['dependent_var']\n",
    "    net_effect_clusters_column = data_matrix_columns['net_effect_clusters']\n",
    "\n",
    "    del input_params\n",
    "    if np.logical_not(np.all(np.all(x1 <= x2))):\n",
    "        raise ValueError(\n",
    "            'Horizontal parameter 1 is NOT <= Horizontal parameter 2 in {}s family of curves'.format(curve_type))\n",
    "\n",
    "    x = np.full((len(net_effect_clusters), particles), np.nan)\n",
    "    y = np.array([])\n",
    "\n",
    "    # Map the predictor variables to the associated y values for all curves / particles simultaneously\n",
    "    for i in range(len(net_effect_clusters)):\n",
    "        cluster_idx = np.nonzero(data[:, net_effect_clusters_column] == net_effect_clusters[i])[0]\n",
    "        X = np.zeros((len(cluster_idx), particles))\n",
    "        for j in range(len(cluster_idx)):\n",
    "            if np.isnan(data[cluster_idx[j], predictor_var_column]):\n",
    "                x[i, :] = 0\n",
    "            else:\n",
    "                # If an activation is falling in the third segment of the curve then get the associated y val\n",
    "                ix3 = data[cluster_idx[j], predictor_var_column] > x2\n",
    "                X[j, ix3] = (np.multiply(np.divide(y4[ix3] - y3[ix3], 1 - x2[ix3]),\n",
    "                                         data[cluster_idx[j], predictor_var_column] - 1)) + y4[ix3]\n",
    "\n",
    "                # If an activation is falling in the first segment of the curve then get the associated y val\n",
    "                ix2 = np.logical_and(np.logical_not(ix3), data[cluster_idx[j], predictor_var_column] > x1)  # seg #1\n",
    "                X[j, ix2] = (np.multiply(np.divide(y3[ix2] - y2[ix2], x2[ix2] - x1[ix2]),\n",
    "                                         data[cluster_idx[j], predictor_var_column] - x1[ix2])) + y2[ix2]\n",
    "\n",
    "                # If an activation is falling in the first segment of the curve then get the associated y val\n",
    "                ix1 = np.logical_not(ix3) & np.logical_not(ix2) & (\n",
    "                        data[cluster_idx[j], predictor_var_column] > 0)  # segment #1\n",
    "                X[j, ix1] = np.multiply(np.divide(y2[ix1] - y1[ix1], x1[ix1]),\n",
    "                                        data[cluster_idx[j], predictor_var_column]) + y1[ix1]\n",
    "\n",
    "                # If an activation is at the intercept of the curve then get the associated y val\n",
    "                ix0 = np.logical_not(ix3) & np.logical_not(ix2) & np.logical_not(ix1) & (\n",
    "                        data[cluster_idx[j], predictor_var_column] == 0)  # Intercept (Boundary condition)\n",
    "                X[j, ix0] = y1[ix0]\n",
    "\n",
    "                # If an item has net effects then taking the sum below will compute the net effects.\n",
    "                # If an item has no net effect then this loop will be executed only once and the sum has no effect\n",
    "                x[i, :] = np.sum(X, axis=0)\n",
    "\n",
    "        # Our model enforces that the DV will need to be unique for items within a net effect cluster\n",
    "        # i.e. all 1's or all 0's\n",
    "        if len(np.unique(data[cluster_idx, dependent_var_column])) != 1:\n",
    "            raise ValueError('Dependent var is NOT unique for net effect cluster {}'.format(i))\n",
    "\n",
    "        # We accumulate the dependent variables for each net effect cluster\n",
    "        y = np.concatenate((y, np.unique(data[cluster_idx, dependent_var_column])))\n",
    "\n",
    "    del X\n",
    "    del ix0\n",
    "    del ix1\n",
    "    del ix2\n",
    "    del ix3\n",
    "    del x1\n",
    "    del x2\n",
    "    del y1\n",
    "    del y2\n",
    "    del y3\n",
    "    del y4\n",
    "    del data\n",
    "    del data_matrix_columns\n",
    "    if np.any(np.isnan(x)):\n",
    "        raise ValueError('NaNs in trials x particles matrix!')\n",
    "    if np.any(np.isinf(x)):\n",
    "        raise ValueError('Inf in trials x particles matrix!')\n",
    "\n",
    "    # Compute z = beta_0 + beta_1 x predictor variable\n",
    "    z = (b1 * x) + b0\n",
    "\n",
    "    return {'w': family_of_distributions(distribution, 'compute_densities', z, y, dist_specific_params),\n",
    "            'net_effects': x,\n",
    "            'dependent_var': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(compute_horz_indpnt_likelihood, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def count_horz_indpnt_particles(input_params):\n",
    "    \"\"\"Use some criterion to carve out the curve space into theory consistent \n",
    "    and theory inconsistent\"\"\"\n",
    "    \n",
    "    if len(input_params) <= 0:\n",
    "        raise ValueError('Missing input parameters!')\n",
    "    if np.logical_not(np.all(np.all(\n",
    "        input_params[0][:, 1] <= input_params[0][:, 2]))):\n",
    "\n",
    "        raise ValueError(\n",
    "            'Horizontal parameter 1 is NOT <= Horizontal parameter 2 in {}s family of curves'.format(\n",
    "                curve_type))\n",
    "\n",
    "    # The different branches of theory-consistent curves can be defined in \n",
    "    # terms of the location of the dip in the curve (the point that \n",
    "    # anchors the weakening part of the curve) and the rise in the curve \n",
    "    # (the point that anchors the strengthening part of the curve). More \n",
    "    # formally, -- The dip in a theory-consistent curve is a point that is \n",
    "    # located horizontally between the left edge of the curve and the rise. \n",
    "    # Within this horizontal range, the dip is the lowest point on the \n",
    "    # curve; it also has to fall below zero on the y-axis. -- The rise in \n",
    "    # a theory-consistent curve is a point that is located horizontally to \n",
    "    # the right of the dip. Within this horizontal range, the rise is the \n",
    "    # highest point on the curve; it also has to fall above zero on the \n",
    "    # y-axis. Branch I: y2 defines the dip and y3 defines the rise -1 <= \n",
    "    # y2 < 0, y2 is the dip so it must fall below zero 0 < y3 <= 1, y3 is \n",
    "    # the rise so it must fall above zero -1 <= y4 <= y3, y4 can hold any \n",
    "    # value that is below the rise (y3) y2 < y1 <= 1, y1 can hold any \n",
    "    # value that is above the dip (y2) Branch II: y2 defines the dip and \n",
    "    # y4 defines the rise -1 <= y2 < 0, y2 is the dip so it must fall \n",
    "    # below zero 0 < y4 <= 1, y4 is the rise so it must fall above zero y2 \n",
    "    # <= y3 <= y4, y3 can hold any value between the dip and the rise y2 < \n",
    "    # y1 <= 1, y1 can hold any value that is above the dip (y2) Branch \n",
    "    # III: y3 defines the dip and y4 defines the rise -1 <= y3 < 0, y3 is \n",
    "    # the dip so it must fall below zero 0 < y4 <= 1, y4 is the rise so it \n",
    "    # must fall above zero y3 < y1 <= 1, y1 can hold any value that is \n",
    "    # above the dip (y3) y3 <= y2 <= 1, y2 can hold any value that is \n",
    "    # above the dip (y3)\n",
    "\n",
    "    # Fetch the indices of the theory consistent particles First two lines \n",
    "    # ensure that the horizontal parameters cannot be 0 OR 1, since that \n",
    "    # would eliminate a line segment altogether\n",
    "    return (input_params[0][:, 1] != 0) & (input_params[0][:, 1] != 1) \\\n",
    "           & (input_params[0][:, 2] != 0) & (input_params[0][:, 2] != 1) \\\n",
    "           & (input_params[0][:, 3] >= -1) & (input_params[0][:, 3] < 0) \\\n",
    "           & (input_params[0][:, 4] > 0) & (input_params[0][:, 4] <= 1) \\\n",
    "           & (input_params[0][:, 5] >= -1) & (input_params[0][:, 5] <= input_params[0][:, 4]) \\\n",
    "           & (input_params[0][:, 0] > input_params[0][:, 3]) & (input_params[0][:, 0] <= 1) \\\n",
    "           & (input_params[0][:, 3] >= -1) & (input_params[0][:, 3] < 0) \\\n",
    "           & (input_params[0][:, 5] > 0) & (input_params[0][:, 5] <= 1) \\\n",
    "           & (input_params[0][:, 4] >= input_params[0][:, 3]) & (input_params[0][:, 4] <= input_params[0][:, 5]) \\\n",
    "           & (input_params[0][:, 0] > input_params[0][:, 3]) & (input_params[0][:, 0] <= 1) \\\n",
    "           & (input_params[0][:, 4] >= -1) & (input_params[0][:, 4] < 0) \\\n",
    "           & (input_params[0][:, 5] > 0) & (input_params[0][:, 5] <= 1) \\\n",
    "           & (input_params[0][:, 0] > input_params[0][:, 4]) & (input_params[0][:, 0] <= 1) \\\n",
    "           & (input_params[0][:, 3] >= input_params[0][:, 4]) & (input_params[0][:, 3] <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(count_horz_indpnt_particles, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def get_horz_indpnt_curve_xy_vals(input_params):\n",
    "    \"\"\"This is the same as compute_likelihood in the sense map the predictor \n",
    "    variable to the curve y val but there are some differences.  \n",
    "    1. We only know the curve parameters and we have to map all the x_values \n",
    "    (0-to-1) to the curve y values where as in compute_likelihood we had \n",
    "    specific x values (predictor variables) and curve parameters  \n",
    "    2. There is NO net effect cluster concept here 3. We DO NOT compute the \n",
    "    pmf as well. Hence parts of the code will look similar but we felt these \n",
    "    two chunks of code will need to be separate\n",
    "    \"\"\"\n",
    "    if len(input_params) <= 0:\n",
    "        raise ValueError('Missing input parameters!')\n",
    "\n",
    "    if len(input_params) > 1:\n",
    "        resolution = input_params[1]\n",
    "    else:\n",
    "        resolution = 4\n",
    "\n",
    "    curve = input_params[0]\n",
    "    if curve.ndim < 2:\n",
    "        curve = np.expand_dims(curve, axis=0)\n",
    "    particles = np.shape(curve[:, 1])[0]\n",
    "    if np.any(curve[:, [0, 3, 4, 5]] < -1) or np.any(curve[:, [0, 3, 4, 5]] > 1):\n",
    "        raise ValueError('Vertical curve parameters exceed bounds [-1, 1]!')\n",
    "    if np.any(curve[:, [1, 2]] < 0) or np.any(curve[:, [1, 2]] > 1):\n",
    "        raise ValueError('Horizontal curve parameters exceed bounds [0, 1]!')\n",
    "\n",
    "    x_value = np.arange(0, 1 + np.power(.1, resolution), np.power(.1, resolution))\n",
    "    x_value = np.matlib.repmat(x_value, particles, 1)\n",
    "    y_value = np.full(np.shape(x_value), np.nan)\n",
    "    out = {}\n",
    "\n",
    "    y1 = np.tile(curve[:, 0][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "    x1 = np.tile(curve[:, 1][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "    x2 = np.tile(curve[:, 2][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "    y2 = np.tile(curve[:, 3][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "    y3 = np.tile(curve[:, 4][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "    y4 = np.tile(curve[:, 5][:, np.newaxis], (1, np.shape(x_value)[1]))\n",
    "\n",
    "    if not np.all(np.all(x1 <= x2)):\n",
    "        raise ValueError(\n",
    "            'Horizontal parameter 1 is NOT <= Horizontal parameter 2 in {} family of curves'.format(\n",
    "                curve_type))\n",
    "\n",
    "    ix3 = x_value > x2  # segment 3\n",
    "    y_value[ix3] = np.multiply(np.divide(\n",
    "        y4[ix3] - y3[ix3], 1 - x2[ix3]), x_value[ix3] - 1) + y4[ix3]\n",
    "\n",
    "    ix2 = np.logical_not(ix3) & (x_value > x1)  # segment 2\n",
    "    y_value[ix2] = np.multiply(np.divide(\n",
    "        y3[ix2] - y2[ix2], x2[ix2] - x1[ix2]), x_value[ix2] - x1[ix2]) + y2[ix2]\n",
    "\n",
    "    ix1 = np.logical_not(ix3) & np.logical_not(ix2) & (x_value > 0)  # segment 1\n",
    "    y_value[ix1] = np.multiply(np.divide(\n",
    "        y2[ix1] - y1[ix1], x1[ix1]), x_value[ix1]) + y1[ix1]\n",
    "\n",
    "    ix0 = np.logical_not(ix3) & np.logical_not(ix2) & np.logical_not(ix1) & (x_value == 0)  # intercept\n",
    "    y_value[ix0] = y1[ix0]\n",
    "\n",
    "    if np.any(np.isnan(y_value)):\n",
    "        raise ValueError('NaNs in trials x particles matrix!')\n",
    "    if np.any(np.isinf(y_value)):\n",
    "        raise ValueError('Inf in trials x particles matrix!')\n",
    "    out['xval'] = x_value\n",
    "    out['yval'] = y_value\n",
    "    if particles == 1:\n",
    "        out['curve_params'] = input_params[0]\n",
    "        out['title_string'] = 'y1={}, x1={}, x2={} y2={}, y3={}, y4={}'.format(\n",
    "            y1[0, 0], x1[0, 0], x2[0, 0], y2[0, 0], y3[0, 0], y4[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(get_horz_indpnt_curve_xy_vals, title_level=3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
