{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp family_of_distributions\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def family_of_distributions(distribution_name, get_info, *varargin):\n",
    "    \"\"\"For each of the family of distributions this script performs specific \n",
    "    computations like number of pdf/pmf, etc.\n",
    "    \n",
    "    This function contains the probability density computation, the \n",
    "    distribution-specific fminunc to optimize the objective function, and the \n",
    "    associated partial derivatives for each of the dependent-variable \n",
    "    distributions that are currently covered by the toolbox (i.e., Bernoulli, \n",
    "    normal)\n",
    "    \n",
    "    **Arguments**:  \n",
    "    - distribution_name: distribution name, string, e.g. 'bernoulli', 'normal'\n",
    "    - get_info: Cues for specific information / computation, string, e.g. \n",
    "        'get_nParams'\n",
    "    - varargin: Is either empty or has arguments depending on the computation\n",
    "    \n",
    "    **Returns** output of all computations.\n",
    "    \"\"\"\n",
    "    if distribution_name == 'bernoulli':\n",
    "        return bernoulli_distribution(get_info, varargin)\n",
    "    elif distribution_name == 'normal':\n",
    "        return normal_distribution(get_info, varargin)\n",
    "    else:\n",
    "        raise ValueError('Invalid distribution!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(family_of_distributions, title_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def bernoulli_distribution(get_info, input_params):\n",
    "    \"\"\"If get_info is `compute_densities`, computes the log probability \n",
    "    densities of the curves specified by input_params using the bernoulli \n",
    "    distribution. Otherwise passes parameters to `fminunc_both_betas`. \n",
    "    \"\"\"\n",
    "    \n",
    "    # --> Compute the log densities. We compute the log(probability function)\n",
    "    if get_info == 'compute_densities':  \n",
    "        if len(input_params) <= 1:\n",
    "            raise ValueError('Missing input parameters!')\n",
    "        z = input_params[0]\n",
    "        y = input_params[1]\n",
    "        del input_params\n",
    "\n",
    "        # Compute fz = 1 / (1 + exp(-z) - Logistic function\n",
    "        fz = 1 / (1 + np.exp(-z))\n",
    "        del z\n",
    "        fz = np.fmax(fz, np.finfo(float).eps)\n",
    "        fz = np.fmin(fz, 1 - np.finfo(float).eps)\n",
    "\n",
    "        # Compute bern_log_pmf = p ^ k + (1 - p) ^ (1 - k). \n",
    "        # http://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    "        # Here p = fz and k = y. \n",
    "        # Taking the log results in y x log(fz) + (1 - y) x log(1 - fz).\n",
    "        return np.sum((np.log(fz).T * y).T + (\n",
    "            np.log(1 - fz).T * np.subtract(1, y)).T, axis=0)\n",
    "\n",
    "    elif get_info == 'fminunc_both_betas':\n",
    "        if len(input_params) <= 1:\n",
    "            raise ValueError('Missing input parameters!')\n",
    "        return lambda betas: fminunc_bernoulli_both(\n",
    "            betas, input_params[0], input_params[1], input_params[2])\n",
    "    else:\n",
    "        raise ValueError('Invalid operation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(bernoulli_distribution, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def fminunc_bernoulli_both(betas, w, net_effects, dependent_var):\n",
    "    \"\"\"Optimizes logistic regression betas using bernoulli cost function F\n",
    "    \n",
    "    **Arguments**:  \n",
    "    - betas: The current betas that were used to compute likelihoods\n",
    "    - w: Weight vector that holds the normalized weights for P particles\n",
    "    - net_effects: Predictor variable Matrix (number of trials x particles)\n",
    "    - dependent_var: Dependent variable Matrix (number of trials x 1)\n",
    "    \n",
    "    **Returns**:\n",
    "    - f: Scalar, Objective function\n",
    "    - g: Vector of length 2 i.e. gradients with respect to beta_0 and beta_1\n",
    "    \"\"\"\n",
    "\n",
    "    beta_0 = betas[0]\n",
    "    beta_1 = betas[1]\n",
    "\n",
    "    z = (beta_1 * net_effects) + beta_0\n",
    "    fz = 1 / (1 + np.exp(-z))\n",
    "    if np.any(np.isinf(fz)):\n",
    "        raise ValueError('Inf in fz matrix!')\n",
    "    fz = np.fmax(fz, np.finfo(float).eps)\n",
    "    fz = np.fmin(fz, 1 - np.finfo(float).eps)\n",
    "\n",
    "    # Cost function\n",
    "    # We will need to maximize the betas but fminunc minimizes hence a -ve.\n",
    "    # Here we compute the log pmf over all trials and then component multiply \n",
    "    # by the weights and then sum them up over all particles\n",
    "    f = -np.sum(w * np.sum((np.log(fz).T * dependent_var).T + (\n",
    "        np.log(1 - fz).T * np.subtract(1, dependent_var)).T, axis=0), axis=0)\n",
    "\n",
    "    # Here we take the partial derivative of log pmf over beta_0 and beta_1 \n",
    "    # respectively, component multiply by the weights and sum them up over all \n",
    "    # particles\n",
    "    g = np.zeros(2)\n",
    "    g[0] = -np.sum(w * np.sum(\n",
    "        (dependent_var - (np.exp(z) / (1 + np.exp(z))).T).T, axis=0), axis=0)\n",
    "    g[1] = -np.sum(w * np.sum((net_effects.T * dependent_var).T - (\n",
    "        (net_effects * np.exp(z)) / (1 + np.exp(z))), axis=0))\n",
    "    if np.any(np.isinf(g)):\n",
    "        raise ValueError('Inf in partial derivative!')\n",
    "    if np.any(np.isnan(g)):\n",
    "        raise ValueError('NaN in partial derivative!')\n",
    "\n",
    "    return f, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(fminunc_bernoulli_both, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide \n",
    "\n",
    "def normal_distribution(get_info, input_params):\n",
    "    \"\"\"If get_info is `compute_densities`, computes the log probability \n",
    "    densities of the curves specified by input_params using the normal \n",
    "    distribution. Otherwise passes parameters to `fminunc_normal_both`. \n",
    "    \"\"\"\n",
    "    if get_info == 'compute_densities':\n",
    "        if len(input_params) <= 2:\n",
    "            raise ValueError('Missing input parameters!')\n",
    "\n",
    "        mu = input_params[0]\n",
    "        y = input_params[1]\n",
    "        dist_specific_params = input_params[2]\n",
    "        sigma = dist_specific_params['sigma']\n",
    "\n",
    "        # Compute log_pdf http://en.wikipedia.org/wiki/Normal_distribution\n",
    "        return np.sum(np.subtract((1 / np.power(sigma, 2)) * np.subtract(\n",
    "            np.multiply(y, mu), np.add(np.multiply(.5, np.power(mu, 2)), \n",
    "                                       np.multiply(.5, np.power(y, 2))))), \n",
    "                      (.5 * np.log(2 * np.pi * np.power(sigma, 2))))\n",
    "\n",
    "    # --> (2), This fetches the right function handle for the fminunc\n",
    "    elif get_info == 'fminunc_both_betas':  \n",
    "        if len(input_params) <= 3:\n",
    "            raise ValueError('Missing input parameters!')\n",
    "\n",
    "        return lambda betas: fminunc_normal_both(\n",
    "            betas, input_params[0], input_params[1], \n",
    "            input_params[2], input_params[3])\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid operation!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(normal_distribution, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def fminunc_normal_both(betas, w, net_effects, dependent_var, dist_specific_params):\n",
    "    \"\"\"Optimizes logistic regression betas using normal cost function F\n",
    "     \n",
    "    **Arguments**:\n",
    "    - betas: The current betas that were used to compute likelihoods\n",
    "    - w: Weight vector that holds the normalized weights for P particles\n",
    "    - net_effects: Predictor variable Matrix (number of trials x particles)\n",
    "    - dependent_var: Dependent variable Matrix (number of trials x 1)\n",
    "    - sigma: Used to specify variance in the Normal distribution\n",
    "    \n",
    "    **Returns**:\n",
    "    - f: Scalar, Objective function\n",
    "    - g: Vector of length 2 i.e. gradients with respect to beta_0 and beta_1\n",
    "    \"\"\"\n",
    "\n",
    "    beta_0 = betas[0]\n",
    "    beta_1 = betas[1]\n",
    "    sigma = dist_specific_params['sigma']\n",
    "\n",
    "    mu = (beta_1 * net_effects) + beta_0\n",
    "\n",
    "    # Cost function\n",
    "    # We will need to maximize the betas but fminunc minimizes hence a -ve.\n",
    "    # Here we compute the log pdf over all trials and then component multiply by the weights\n",
    "    # and then sum them up over all particles\n",
    "    f = -np.sum(\n",
    "        w * np.sum(np.subtract(np.multiply((1 / np.power(sigma, 2)), np.subtract(np.multiply(dependent_var, mu), np.add(\n",
    "            np.multiply(.5, np.power(mu, 2)), np.multiply(.5, np.power(dependent_var, 2))))),\n",
    "                               (.5 * np.log(2 * np.pi * np.power(sigma, 2))))))\n",
    "\n",
    "    # Here we take the partial derivative of log pdf over beta_0 and beta_1 respectively,\n",
    "    # component multiply by the weights and sum them up over all particles\n",
    "    g = [-np.sum(w * np.sum(\n",
    "        (1 / np.power(sigma, 2)) * np.subtract(dependent_var, np.add(beta_0, np.multiply(beta_1, net_effects))))),\n",
    "         -np.sum(w * np.sum(np.multiply(np.divide(net_effects, np.power(sigma, 2)),\n",
    "                                        np.subtract(dependent_var, np.add(beta_0, np.multiply(beta_1, net_effects))))))]\n",
    "\n",
    "    if np.any(np.isinf(g)):\n",
    "        raise ValueError('Inf in partial derivative!')\n",
    "    if np.any(np.isnan(g)):\n",
    "        raise ValueError('NaN in partial derivative!')\n",
    "\n",
    "    return f, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(fminunc_normal_both, title_level=3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
