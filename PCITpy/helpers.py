# AUTOGENERATED! DO NOT EDIT! File to edit: Additional_Helper_Functions.ipynb (unless otherwise specified).

__all__ = ['likratiotest', 'truncated_normal', 'scale_data']

# Cell
# hide
from scipy import stats

def likratiotest(l1, l0, k1, k0):
    """Performs the likelihood ratio test for nested models.

    **Arguments**:
    - L1: log-likelihood for alternative model
    - L0: log-likelihood for the null model
    - K1: number of parameters for alternative model
    - K0: number of parameters for null model (K1 > K0)

    **Returns**:
    - D: deviate score: -2*log(L1-L0)
    - p: p-value from chi-squared test with degrees of freedom = K1-K0
    """
    D = -2 * (l0 - l1)  # deviance score
    df = k1 - k0  # degrees of freedom
    p = stats.chi2.sf(D, df)  # chi-square test
    return D, p

# Cell
# hide
from scipy import special
from numpy.random import rand
from math import sqrt


def truncated_normal(a, b, mu, sigma, n):
    """Generates N samples from a truncated normal distribution with mean=mu,
    sigma=sigma and with bounds A and B.

    We use this function in our toolbox to add noise from a truncated Gaussian
    distribution.

    **Arguments**:
    - A: lower bound
    - B: upper bound
    - mu: mean
    - sigma: sigma, standard deviation
    - N: number of samples

    **Returns** array of length N containing mean + truncated Gaussian noise with
    mean=mu, sigma=sigma, between bounds A and B
    """

    if (b - a) < 0:
        raise ValueError('Lower bound is greater then upper bound!')
    elif sigma <= 0:
        raise ValueError('Sigma is <= 0!')

    phi_l = 0.5 * special.erfc(-(((a - mu) / sigma) / sqrt(2)))
    phi_r = 0.5 * special.erfc(-(((b - mu) / sigma) / sqrt(2)))

    # Refer to http://www.maths.uq.edu.au/~chancc/10Fstat3001/ass4sol.pdf for truncated normal dist sampling below --
    # If this source does not exist then refer to code in the link below,
    # http://www.wiley.com/legacy/wileychi/koopbayesian/supp/normt_rnd.m
    return mu + sigma * (sqrt(2) * special.erfinv(2 * (phi_l + (phi_r - phi_l) * rand(int(n))) - 1))

# Cell
# hide
import numpy as np


def scale_data(data, lower=-1.0, upper=1.0):
    """Scale the elements of all the column vectors in Data within the range
    of [Lower Upper]; default range is [-1 1]

    We use this function in our toolbox to scale the predictor variable
    between 0 and 1.

    **Arguments**:
    - Data: data, numeric vector
    - Lower: lower range, numeric
    - Upper: upper range, numeric

    **Returns**:
    - scaled: 1xN array containing scaled data
    """
    if lower > upper:
        raise ValueError('Wrong lower of upper values!')

    max_v = np.amax(data, axis=0)
    min_v = np.amin(data, axis=0)
    shape = np.shape(data)

    if len(shape) < 2:
        r, c = 1, shape[0]
    elif len(shape) > 2:
        r, c = shape[0], np.prod(shape[1:])
    else:
        r, c = shape

    scaled = ((data - np.ones((r, 1)) * min_v) * (
            np.ones((r, 1)) * (
            (upper - lower) * (
            np.ones((1, c)) / (max_v - min_v))))) + lower

    return scaled