{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Make the Call to compute_trunc_likes not so slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import special\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = .05\n",
    "bounds = np.array([[-1,  1],\n",
    "       [ 0,  1],\n",
    "       [ 0,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1]])\n",
    "which_param = 0\n",
    "\n",
    "nth_grp_lvl_param = np.load('../nth_grp_lvl_param.npy')\n",
    "nth_prev_iter_curve_param = np.load('../nth_prev_iter_curve_param.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -79.48709185, -150.99830714,  -29.47795205, ...,  -71.2268334 ,\n",
       "        -105.3245468 ,  -54.88876175],\n",
       "       [-121.67798878, -207.17952733,  -57.37657632, ..., -111.4520988 ,\n",
       "        -153.09262719,  -27.67273552],\n",
       "       [ -72.56912216, -141.4638131 ,  -25.23297847, ...,  -64.67648373,\n",
       "         -97.3635107 ,  -60.95154324],\n",
       "       ...,\n",
       "       [-472.7931511 , -629.58835366, -335.65936243, ..., -452.55054658,\n",
       "        -532.62870847,  -25.09529379],\n",
       "       [-153.45980969, -247.96357878,  -79.96187393, ..., -141.96911203,\n",
       "        -188.4631494 ,  -14.79389256],\n",
       "       [-203.46263452, -310.43270377, -117.22934177, ..., -190.22042961,\n",
       "        -243.4356123 ,   -2.95057406]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([compute_trunc_likes(nth_grp_lvl_param[:, i], nth_prev_iter_curve_param[i])\n",
    "                                    for i in range(len(nth_prev_iter_curve_param))]).T\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -79.48709185, -150.99830714,  -29.47795205,    1.72411827,\n",
       "        -58.22374008,   -1.62280954,  -52.41845844,   -2.82212032,\n",
       "        -23.82987544, -115.64009915, -190.95174464,  -76.72652552,\n",
       "        -51.11403342,  -69.8290162 ,  -97.69304995,   -9.24178285,\n",
       "         -0.26000773,  -71.2268334 , -105.3245468 ,  -54.88876175])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.6 ms ± 8.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test = np.array([compute_trunc_likes(nth_grp_lvl_param[:, i], nth_prev_iter_curve_param[i])\n",
    "                                    for i in range(len(nth_prev_iter_curve_param))]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize?\n",
    "Instead of acting over a single mu or column, I need operations that use the entire array such that `mu` is a vector and `x` is a 2-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = nth_prev_iter_curve_param\n",
    "x = nth_grp_lvl_param\n",
    "\n",
    "log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "    -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "        -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.1 ms ± 1.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mu = nth_prev_iter_curve_param\n",
    "x = nth_grp_lvl_param\n",
    "\n",
    "log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "    -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "        -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem the code needs further alterations to support vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "Let's test a call to compute_trunc_likes using the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.1 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Needs to Be Several Times Faster. Where is the Bottleneck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# get rid of first term\n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# then the second hidden in the log term\n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log((np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# the entire second log term\n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) ) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2))))))))- np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# the final term, the only one using x\n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the last term. I need to focus all efforts on optimizing the last term. Any  particular part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.power(np.divide(x - mu, tau), 2)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(x - mu, 2))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bottleneck is np.power\n",
    "It's about 82ms with the full equation. The full term is `np.multiply(.5, np.power(np.divide(x - mu, tau), 2))`. Without it, speed is 19.8us. The contribution of each part?\n",
    "\n",
    "Removing np.multiply obtains a runtime of 78.5ms.\n",
    "Removing np.power obtains 22.1ms.\n",
    "Removing divide gets 79.7ms.\n",
    "Removing x-mu gets 77.6.\n",
    "\n",
    "So the most impactful statement is np.power. Can I make it faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.7 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.power(np.divide(x - mu, tau), 2))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 ms ± 177 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice but I still need it to be 4 times faster to be MATLAB tier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the Top Bottleneck Now?\n",
    "The full term is now `np.multiply(.5, np.divide(x - mu, tau) ** 2)`. Takes 26.2ms to run. I need it down to 6.5ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.2 ms ± 1.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - (np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, (x - mu) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau))\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime is similar across all operations now. While removing them all obtains huge gains, removing any individual operation only gives about 5ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 ms ± 57.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - (x - mu)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if it were just an addition operation, it'd take 12ms instead of my 6.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number Precision Experiment\n",
    "Let's take a step back and see if PCIT does ok with lower number precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_grp_lvl_param = nth_grp_lvl_param.astype('float32')\n",
    "nth_prev_iter_curve_param = nth_prev_iter_curve_param.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 ms ± 330 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half precision grants half-speed runtime. Does PCIT work fine that way?\n",
    "\n",
    "```\n",
    "Start time 12/17 9:53\n",
    "********** START OF MESSAGES **********\n",
    "0 trials are dropped since they are regarded as outliers\n",
    "********** END OF MESSAGES **********\n",
    "Betas: 0, 1\n",
    "EM Iteration: 0\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 1243.911318\n",
    "         Iterations: 6\n",
    "         Function evaluations: 8\n",
    "         Gradient evaluations: 8\n",
    "Betas: 0.10592798970016724, 0.6316629314995463\n",
    "EM Iteration: 1\n",
    "```\n",
    "\n",
    "Not too far off from Betas: 0.0882896038554186, 0.6902758140586037. But definitely meaningfully off. And the extra benefit isn't double. I found an improve from 4x slower to just 3x slower. So I'm ambivalent about the idea. But at least I've figured out how to institute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can We Vectorize The Loop Over Params?\n",
    "To vectorize, I have to use every row of `param` at once.\n",
    "`nth_grp_lvl_param` is just a selected column of param, repeated for 20 columns. Could I avoid doing that?\n",
    "`idx` selects a subset of rows of `prev_iter_curve_param` to fill `nth_prev_iter_curve_param` while `npm` similarly picks the column filling the variable.\n",
    "\n",
    "`nth_grp_lvl_param` has shape 100,000x20, while `prev_iter_curve_param` has shape 20. Each entry in `prev_ter_curve_param` is broadcast to each column in `nth_grp_lvl_param` during all this math - well, after a bit of computation on those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6581, -0.8944, -0.4167,  0.0225,  0.5296, -0.1555,  0.5025,\n",
       "       -0.176 , -0.3794,  0.7477,  0.9636, -0.6472, -0.5352, -0.6191,\n",
       "        0.6868,  0.2184,  0.0886, -0.6249, -0.7523,  0.5142])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nParam = 6\n",
    "tau = .05\n",
    "bounds = np.array([[-1,  1],\n",
    "       [ 0,  1],\n",
    "       [ 0,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1]])\n",
    "which_param = 0\n",
    "idx = 0\n",
    "reduced_nParticles = 20\n",
    "\n",
    "nth_grp_lvl_param = np.load('../nth_grp_lvl_param.npy')\n",
    "nth_prev_iter_curve_param = np.load('../nth_prev_iter_curve_param.npy')\n",
    "nth_prev_iter_curve_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "result = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nth_grp_lvl_param = nth_grp_lvl_param\n",
    "alt_nth_prev_iter_curve_param = np.tile(nth_prev_iter_curve_param, (6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100000,20) (20,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-95528567cf86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompute_trunc_likes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malt_nth_grp_lvl_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt_nth_prev_iter_curve_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-7916e335fa79>\u001b[0m in \u001b[0;36mcompute_trunc_likes\u001b[1;34m(x, mu)\u001b[0m\n\u001b[0;32m     11\u001b[0m         -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n\u001b[0;32m     12\u001b[0m             -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n\u001b[1;32m---> 13\u001b[1;33m             -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100000,20) (20,6) "
     ]
    }
   ],
   "source": [
    "compute_trunc_likes(alt_nth_grp_lvl_param, alt_nth_prev_iter_curve_param.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(alt_nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6581, -0.8944, -0.4167,  0.0225,  0.5296, -0.1555,  0.5025,\n",
       "       -0.176 , -0.3794,  0.7477,  0.9636, -0.6472, -0.5352, -0.6191,\n",
       "        0.6868,  0.2184,  0.0886, -0.6249, -0.7523,  0.5142])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nth_prev_iter_curve_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I can get the same result using just a single column of `nth_grp_lvl_param` and a transpose. Could that improve runtime? How do I find out? Compare runtime against using the full number. It actu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npm in range(nParam):\n",
    "    which_param = npm\n",
    "    nth_grp_lvl_param = np.tile(\n",
    "        param[:, npm].reshape(-1, 1), (1, reduced_nParticles))\n",
    "    nth_prev_iter_curve_param = prev_iter_curve_param[target_indices, npm]\n",
    "    trunc_likes = compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)\n",
    "    prob_grp_lvl_curve = np.add(prob_grp_lvl_curve, trunc_likes)\n",
    "\n",
    "    if np.any(np.isnan(prob_grp_lvl_curve)):\n",
    "        raise ValueError('NaNs in probability of group level curves matrix!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can I Optimize The Other Operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 ms ± 1.68 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -79.48709185, -150.99830714,  -29.47795205, ...,  -71.2268334 ,\n",
       "        -105.3245468 ,  -54.88876175],\n",
       "       [-121.67798878, -207.17952733,  -57.37657632, ..., -111.4520988 ,\n",
       "        -153.09262719,  -27.67273552],\n",
       "       [ -72.56912216, -141.4638131 ,  -25.23297847, ...,  -64.67648373,\n",
       "         -97.3635107 ,  -60.95154324],\n",
       "       ...,\n",
       "       [-472.7931511 , -629.58835366, -335.65936243, ..., -452.55054658,\n",
       "        -532.62870847,  -25.09529379],\n",
       "       [-153.45980969, -247.96357878,  -79.96187393, ..., -141.96911203,\n",
       "        -188.4631494 ,  -14.79389256],\n",
       "       [-203.46263452, -310.43270377, -117.22934177, ..., -190.22042961,\n",
       "        -243.4356123 ,   -2.95057406]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - (.5 * (((x - mu)/ tau) ** 2))\n",
    "    return log_likelihood\n",
    "\n",
    "compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus On Just The Time-Consuming Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9 ms ± 1.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def quickie(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "        \n",
    "    return np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "\n",
    "quickie(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 ms ± 261 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def quickie(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "        \n",
    "    return (((x - mu)/ constant) ** 2)\n",
    "\n",
    "quickie(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = tau/np.sqrt(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I can stick the `.5` multiplication term onto `tau`, so that all the arithmetic broadcasting only happens once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapse The Arithmetic\n",
    "So I can stick the `.5` multiplication term onto `tau`, so that all the arithmetic broadcasting only happens once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = .05\n",
    "bounds = np.array([[-1,  1],\n",
    "       [ 0,  1],\n",
    "       [ 0,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1],\n",
    "       [-1,  1]])\n",
    "which_param = 0\n",
    "\n",
    "nth_grp_lvl_param = np.load('../nth_grp_lvl_param.npy')\n",
    "nth_prev_iter_curve_param = np.load('../nth_prev_iter_curve_param.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.2 ms ± 1.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - np.multiply(.5, np.divide(x - mu, tau) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_grp_lvl_param = nth_grp_lvl_param.astype('float32')\n",
    "nth_prev_iter_curve_param = nth_prev_iter_curve_param.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5 ms ± 173 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "def compute_trunc_likes(x, mu):\n",
    "    global tau, bounds, which_param\n",
    "\n",
    "    if tau <= 0:\n",
    "        raise ValueError('Tau is <= 0!')\n",
    "\n",
    "    # This ugly thing below is a manifestation of log(1 ./ (tau .* (normcdf((bounds(which_param, 2) - mu) ./ tau) -\n",
    "    # normcdf((bounds(which_param, 1) - mu) ./ tau))) .* normpdf((x - mu) ./ tau)) Refer to\n",
    "    # http://en.wikipedia.org/wiki/Truncated_normal_distribution for the truncated normal distribution\n",
    "    log_likelihood = -(np.log(tau) + np.log(np.multiply(0.5, special.erfc(\n",
    "        -np.divide(bounds[which_param, 1] - mu, np.multiply(tau, math.sqrt(2))))) + (np.multiply(-0.5, special.erfc(\n",
    "            -np.divide(bounds[which_param, 0] - mu, np.multiply(tau, math.sqrt(2)))))))) + np.multiply(\n",
    "            -.5, np.log(2) + np.log(np.pi)) - (np.divide(x - mu, tau/np.sqrt(.5)) ** 2)\n",
    "    return log_likelihood\n",
    "\n",
    "compute_trunc_likes(nth_grp_lvl_param, nth_prev_iter_curve_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
